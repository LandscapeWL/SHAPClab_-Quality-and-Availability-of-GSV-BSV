{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f28b7809",
   "metadata": {},
   "source": [
    "# 处理单个文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f62b2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总行数: 207265\n",
      "有空字段的行数: 64680\n",
      "无空字段的行数: 142585\n",
      "不存在空字段的行中svid重复出现的行数: 34663\n"
     ]
    }
   ],
   "source": [
    "# 导入pandas库\n",
    "import pandas as pd\n",
    "\n",
    "# 加载CSV文件\n",
    "file_path = './1.result_csv/search_baidu_200m.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 计算文件中的总行数\n",
    "total_rows = len(df)\n",
    "\n",
    "# 计算存在空字段的行数\n",
    "rows_with_empty_fields = df.isnull().any(axis=1).sum()\n",
    "\n",
    "# 计算没有空字段的行数\n",
    "rows_without_empty_fields = df.dropna()\n",
    "rows_without_empty_fields_count = len(rows_without_empty_fields)\n",
    "\n",
    "# 计算 'svid' 重复出现的次数（不包括第一次出现）\n",
    "# 这里使用 duplicated 方法，并设置 keep='first' 参数\n",
    "# 这样就只标记第一次出现之后的重复行\n",
    "# 然后使用 nunique 方法计算这些重复行中不同 'svid' 的数量\n",
    "duplicate_svid_count = rows_without_empty_fields[rows_without_empty_fields.duplicated(subset='svid', keep='first')]['svid'].nunique()\n",
    "\n",
    "# 打印结果\n",
    "print(f\"总行数: {total_rows}\")\n",
    "print(f\"有空字段的行数: {rows_with_empty_fields}\")\n",
    "print(f\"无空字段的行数: {rows_without_empty_fields_count}\")\n",
    "print(f\"不存在空字段的行中svid重复出现的行数: {duplicate_svid_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352281b2",
   "metadata": {},
   "source": [
    "# 处理所有文件，把结果储存到csv文件中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7030e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在处理: ./2.result_calculate/search_google_20m.csv\n",
      "正在处理: ./2.result_calculate/search_baidu_50m.csv\n",
      "正在处理: ./2.result_calculate/search_baidu_100m.csv\n",
      "正在处理: ./2.result_calculate/search_baidu_5m.csv\n",
      "正在处理: ./2.result_calculate/search_google_40m.csv\n",
      "正在处理: ./2.result_calculate/search_baidu_10m.csv\n",
      "正在处理: ./2.result_calculate/search_baidu_30m.csv\n",
      "正在处理: ./2.result_calculate/search_baidu_40m.csv\n",
      "正在处理: ./2.result_calculate/search_google_10m.csv\n",
      "正在处理: ./2.result_calculate/search_google_30m.csv\n",
      "正在处理: ./2.result_calculate/search_baidu_20m.csv\n",
      "正在处理: ./2.result_calculate/search_google_50m.csv\n",
      "正在处理: ./2.result_calculate/search_google_100m.csv\n",
      "正在处理: ./2.result_calculate/search_google_5m.csv\n",
      "正在处理: ./2.result_calculate/search_baidu_200m.csv\n",
      "正在处理: ./2.result_calculate/search_google_200m.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 设置CSV文件所在的文件夹路径\n",
    "folder_path = './1.result_calculate/'\n",
    "\n",
    "# 获取文件夹中所有CSV文件的列表\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "# 初始化一个空的DataFrame用于存储结果\n",
    "results_df = pd.DataFrame(columns=['name', 'total_rows', 'rows_with_empty_fields', 'rows_without_empty_fields', 'duplicate_svid_count'])\n",
    "\n",
    "# 遍历每个CSV文件\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    print('正在处理:',file_path)\n",
    "    # 执行之前的数据处理步骤\n",
    "    total_rows = len(df)\n",
    "    rows_with_empty_fields = df.isnull().any(axis=1).sum()\n",
    "    rows_without_empty_fields = df.dropna()\n",
    "    rows_without_empty_fields_count = len(rows_without_empty_fields)\n",
    "    duplicate_svid_count = rows_without_empty_fields[rows_without_empty_fields.duplicated(subset='svid', keep='first')]['svid'].nunique()\n",
    "\n",
    "    # 将结果作为新行添加到结果DataFrame中\n",
    "    new_row = pd.DataFrame({'name': [file],\n",
    "                            'total_rows': [total_rows],\n",
    "                            'rows_with_empty_fields': [rows_with_empty_fields],\n",
    "                            'rows_without_empty_fields': [rows_without_empty_fields_count],\n",
    "                            'duplicate_svid_count': [duplicate_svid_count]})\n",
    "    results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "\n",
    "# 保存结果到CSV文件\n",
    "results_df.to_csv('./2.result_satistic/final_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4360bbd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
